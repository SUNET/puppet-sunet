#!/usr/bin/env python3
#
# Copyright (c) 2016, 2018, 2019, 2023 SUNET
# All rights reserved.
#
#   Redistribution and use in source and binary forms, with or
#   without modification, are permitted provided that the following
#   conditions are met:
#
#     1. Redistributions of source code must retain the above copyright
#        notice, this list of conditions and the following disclaimer.
#     2. Redistributions in binary form must reproduce the above
#        copyright notice, this list of conditions and the following
#        disclaimer in the documentation and/or other materials provided
#        with the distribution.
#     3. Neither the name of the SUNET nor the names of its
#        contributors may be used to endorse or promote products derived
#        from this software without specific prior written permission.
#
# THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
# "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
# LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS
# FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE
# COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT,
# INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING,
# BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
# LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
# CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT
# LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN
# ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE
# POSSIBILITY OF SUCH DAMAGE.
#
# Author: Fredrik Thulin <fredrik@thulin.net>
#
"""
Nagios check to verify that docker containers are running.
"""

import argparse
import datetime
import json
import logging
import os
import re
import subprocess
import sys
from typing import Any, Dict, List, NewType, Optional, Tuple, cast

import yaml

default_debug = False
default_init_d = False
default_systemd = True
default_runtime_ok = 120
default_runtime_warn = 60

# Nagios plugin exit status codes
STATUS = {
    "OK": 0,
    "WARNING": 1,
    "CRITICAL": 2,
    "UNKNOWN": 3,
}


Arguments = NewType("Arguments", argparse.Namespace)


def parse_args() -> Arguments:
    """
    Parse the command line arguments
    """
    parser = argparse.ArgumentParser(
        description="Docker container status Nagios check",
        add_help=True,
        formatter_class=argparse.ArgumentDefaultsHelpFormatter,
    )

    parser.add_argument(
        "--debug",
        dest="debug",
        action="store_true",
        default=default_debug,
        help="Enable debug operation",
    )
    parser.add_argument(
        "--systemd",
        dest="systemd",
        action="store_true",
        default=default_systemd,
        help="No-op flag. Will be removed in a future version.",
    )
    parser.add_argument(
        "--runtime_ok",
        dest="runtime_ok",
        type=int,
        default=default_runtime_ok,
        help="Number of seconds a container should have been running to be considered OK",
    )
    parser.add_argument(
        "--runtime_warn",
        dest="runtime_warn",
        type=int,
        default=default_runtime_warn,
        help="Number of seconds a container should have been running to be considered non-critical",
    )
    parser.add_argument(
        "--service",
        dest="service",
        type=str,
        default=None,
        help="Name of specific service to check",
    )

    return cast(Arguments, parser.parse_args())


def collect_systemd(args: Arguments, logger: logging.Logger) -> List[str]:
    """
    Deduce the name of all docker containers expected to be running from service files in /etc/systemd/system

    :returns: Docker container names
    """
    res: List[str] = []
    path = "/etc/systemd/system"
    logger.debug(f"Looking for files in {path!r}")
    files = [this for this in os.listdir(path) if os.path.isfile(os.path.join(path, this))]
    for this in files:
        if not this.endswith(".service"):
            continue
        if args.service and this != f"{args.service}.service":
            continue

        compose = collect_compose_services(os.path.join(path, this), logger)

        if compose:
            res += compose
        else:
            match = re.match(r"docker-(.+)\.service$", this)
            if match:
                res.append(match.group(1))
    return res


def collect_compose_services(fn: str, logger: logging.Logger) -> List[str]:
    """
    Look for systemd services that start containers using Docker compose.
    The services should be created using sunet::docker_compose_service in order to have
    COMPOSE_FILE and SERVICE_NAME metadata in the top comment.

    :type fn: str
    :type logger: logging.Logger

    :returns: Docker container names
    """
    res: List[str] = []
    re_compose_file = re.compile(r"^#\s*COMPOSE_FILE=(.+?)\s*$")
    compose_file = _get_compose_metadata(fn, re_compose_file, logger)
    if compose_file:
        # docker-compose uses directory of file as service-name
        # e.g. for file /path/to/something/docker-compose.yml the service-name is 'something'
        service_name = os.path.basename(os.path.dirname(compose_file))
        res += _collect_compose_service(compose_file, service_name, logger)
    return res


# TODO: Type re_compose_file as re.Pattern[str] when we can drop Python 3.8 support
def _get_compose_metadata(filename: str, re_compose_file: Any, logger: logging.Logger) -> Optional[str]:
    logger.debug(f"Trying to find compose-file reference in file {filename!s}")
    with open(filename) as fd:
        for line in fd.readlines():
            if not line.startswith("#"):
                return None
            m = re_compose_file.match(line)
            if m:
                return m.group(1)


def _collect_compose_service(compose_file: str, service_name: str, logger: logging.Logger) -> List[str]:
    """
    Load a docker-compose file and return a list of containers one could expect to be running.

    :returns: Docker container names
    """
    res: List[str] = []
    with open(compose_file) as fd:
        data = yaml.safe_load(fd)
        # Check that we have a version 2 or 3 compose file.
        # We don't know how services will be defined in future versions, so we don't accept them.
        version = data.get("version", "x")
<% if @facts['dockerhost2'] =! 'yes' %>
        if version[0] not in ["2", "3"]:
            logger.debug(f'Skipping {compose_file!s}, unknown version "{version!r}"')
            return []
<% end %>
        for service in data.get("services", []):
            container_name = data["services"][service].get("container_name", f"{service_name!s}<%= @container_name_delimiter %>{service!s}<%= @container_name_delimiter %>1")
            res.append(container_name)
    return res


def docker_inspect(container: str, logger: logging.Logger) -> Optional[Dict[str, Any]]:
    cmd = ["/usr/bin/docker", "inspect", container]
    proc = subprocess.Popen(
        cmd,
        cwd="/",
        stdout=subprocess.PIPE,
        stderr=subprocess.STDOUT,
        close_fds=True,
    )
    (stdout, _stderr) = proc.communicate()
    try:
        data = json.loads(stdout.decode("utf-8"))
    except ValueError as exc:
        logger.error("Failed parsing output of {!s}: {!s}".format(" ".join(cmd), exc))
        logger.debug(f"Unparsable output was:\n{stdout!r}")
        return None
    # data is a list of dicts, return the first dict
    return data[0]


def calc_running_seconds(started_at: str) -> float:
    # It is shockingly hard to parse an RFC3389 time string in Python
    # without installing additional modules. I know this is a hack.
    started_at = started_at.split(".")[0]
    _started_at = datetime.datetime.strptime(started_at, "%Y-%m-%dT%H:%M:%S")
    now = datetime.datetime.utcnow()
    delta = now - _started_at
    return delta.total_seconds()


def timestr(seconds: float) -> str:
    seconds = int(seconds)
    days = 0
    hours = 0
    mins = 0
    if seconds >= 86400:
        days = int(seconds / 86400)
        seconds = seconds % 86400
    if seconds >= 3600:
        hours = int(seconds / 3600)
        seconds = seconds % 3600
    if seconds >= 60:
        mins = int(seconds / 60)
        seconds = seconds % 60

    if days:
        return f"{days!s}d{hours!s}h"
    if hours:
        return f"{hours!s}h{mins!s}m"
    if mins:
        return f"{mins!s}m{seconds!s}s"
    return f"{seconds!s}s"


def check_containers(expect: List[str], args: Arguments, logger: logging.Logger) -> Tuple[str, str, str]:
    critical: List[str] = []
    warning: List[str] = []
    ok: List[str] = []

    for this in expect:
        logger.debug(f"Docker inspect {this!r}")
        data = docker_inspect(this, logger)
        if not data:
            # try to find containers started with docker-compose run too
            if this.endswith("_1"):
                data = docker_inspect(this[:-2] + "_run_1", logger)
                if data:
                    # update 'this' for logging below
                    this = this[:-2] + "_run_1"
        if not data:
            critical.append(f"{this!s} not found")
            continue
        try:
            status = data["State"]["Status"]
            running = data["State"]["Running"]
            started_at = data["State"]["StartedAt"]
            health_status = None
            labels: Dict[str, str] = {}
            if 'Config' in data and 'Labels' in data['Config']:
                labels = data['Config']['Labels']
            for this_label in labels:
                if this_label.startswith('se.sunet.'):
                    logger.debug(f"Sunet label spotted: {this_label}={labels[this_label]}")

            if "Health" in data["State"] and "Status" in data["State"]["Health"]:
                health_status = data["State"]["Health"]["Status"]

            logger.debug(
                "{!s}: status {!s}, running {!s}, started_at {!s}, health_status {!s}".format(
                    this, status, running, started_at, health_status
                )
            )
        except KeyError:
            warning.append(f"{this!s} unparsable")
            continue

        if "se.sunet.check_docker_containers" in labels:
            if labels["se.sunet.check_docker_containers"] == "run_once":
                # Run-once containers run once when a compose setup starts, but then exit.
                # For these jobs, we check that the exit status was 0.
                _exit_code = data["State"]["ExitCode"]
                logger.debug(f"Exit code: {_exit_code}, status: {status}")
                msg = f"{this!s}[run-once exit={_exit_code}]"
                if status == "exited":
                    if _exit_code == 0:
                        ok.append(msg)
                    else:
                        critical.append(msg)
                continue

        if not running:
            critical.append(f"{this!s} not running")
            continue

        running_seconds = None
        runtime_str = "(unknown start time)"
        if started_at.endswith("Z"):
            running_seconds = calc_running_seconds(started_at)
            runtime_str = timestr(running_seconds)

        msg = f"{this!s}[{status!s} {runtime_str!s}]"

        if health_status is not None:
            msg = f"{this!s}[{health_status!s} {runtime_str!s}]"
            if health_status == "unhealthy":
                critical.append(msg)
                continue
            if health_status != "healthy":
                warning.append(msg)
                continue

        # Check how long container has been running.
        if running_seconds is not None:
            if running_seconds >= args.runtime_ok:
                ok.append(msg)
            elif running_seconds >= args.runtime_warn:
                warning.append(msg)
            else:
                critical.append(msg)
            continue
        else:
            ok.append(msg)
            continue

    return ", ".join(sorted(critical)), ", ".join(sorted(warning)), ", ".join(sorted(ok))


def main(args: Arguments, logger: logging.Logger) -> int:

    expect = collect_systemd(args, logger)

    logger.debug(f"Expecting the following Docker containers to be running: {expect!r}")

    if not len(expect):
        print("UNKNOWN: No containers specified")
        return STATUS["UNKNOWN"]

    critical, warning, ok = check_containers(expect, args, logger)

    output: List[str] = []
    if critical:
        output.append(f"CRITICAL: {critical!s}")
    if warning:
        output.append(f"WARNING: {warning!s}")
    if ok:
        output.append(f"OK: {ok!s}")

    print("{!s}".format(", ".join(output)))

    if critical:
        return STATUS["CRITICAL"]
    if warning:
        return STATUS["WARNING"]
    if ok:
        return STATUS["OK"]

    return STATUS["UNKNOWN"]


if __name__ == "__main__":
    try:
        args = parse_args()

        # This is the root log level
        level = logging.INFO
        if args.debug:
            level = logging.DEBUG
        logging.basicConfig(
            level=level, stream=sys.stderr, format="%(asctime)s: %(threadName)s %(levelname)s %(message)s"
        )
        logger = logging.getLogger("check_docker_containers")

        sys.exit(main(args, logger))
    except KeyboardInterrupt:
        pass
